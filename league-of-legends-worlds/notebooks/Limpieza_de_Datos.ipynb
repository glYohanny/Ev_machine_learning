{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETAPA 3: LIMPIEZA DE DATOS - League of Legends Worlds\n",
    "\n",
    "## Objetivos:\n",
    "1. Documentar el proceso de limpieza de datos\n",
    "2. Explicar las decisiones tomadas en cada paso\n",
    "3. Mostrar el impacto de la limpieza en la calidad de los datos\n",
    "4. Validar la consistencia de los datos limpios\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importar Librerías y Cargar Datos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configurar visualizaciones\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Librerías importadas correctamente\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos originales\n",
    "champions_raw = pd.read_csv('../data/01_raw/champions_stats.csv', encoding='latin-1')\n",
    "matches_raw = pd.read_csv('../data/01_raw/matchs_stats.csv', encoding='latin-1')\n",
    "players_raw = pd.read_csv('../data/01_raw/players_stats.csv', encoding='latin-1')\n",
    "\n",
    "print(\"Datos originales cargados:\")\n",
    "print(f\"- Champions: {champions_raw.shape}\")\n",
    "print(f\"- Matches: {matches_raw.shape}\")\n",
    "print(f\"- Players: {players_raw.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Análisis de Calidad de Datos Originales\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_data_quality(df, dataset_name):\n",
    "    \"\"\"Analiza la calidad de un dataset\"\"\"\n",
    "    print(f\"\\n=== ANÁLISIS DE CALIDAD: {dataset_name.upper()} ===\")\n",
    "    print(f\"Dimensiones: {df.shape}\")\n",
    "    print(f\"\\nValores faltantes por columna:\")\n",
    "    missing = df.isnull().sum()\n",
    "    missing_pct = (missing / len(df)) * 100\n",
    "    missing_df = pd.DataFrame({\n",
    "        'Valores_Faltantes': missing,\n",
    "        'Porcentaje': missing_pct\n",
    "    })\n",
    "    print(missing_df[missing_df['Valores_Faltantes'] > 0])\n",
    "    \n",
    "    print(f\"\\nDuplicados: {df.duplicated().sum()}\")\n",
    "    print(f\"\\nTipos de datos:\")\n",
    "    print(df.dtypes.value_counts())\n",
    "    \n",
    "    return missing_df\n",
    "\n",
    "# Analizar calidad de datos originales\n",
    "champions_missing = analyze_data_quality(champions_raw, \"Champions\")\n",
    "matches_missing = analyze_data_quality(matches_raw, \"Matches\")\n",
    "players_missing = analyze_data_quality(players_raw, \"Players\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Limpieza de Datos de Campeones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_champions_data_detailed(df):\n",
    "    \"\"\"Limpia datos de campeones con explicaciones detalladas\"\"\"\n",
    "    print(\"=== LIMPIEZA DE DATOS DE CAMPEONES ===\")\n",
    "    original_shape = df.shape\n",
    "    \n",
    "    # 1. Eliminar filas con valores faltantes críticos\n",
    "    print(\"\\n1. Eliminando filas con valores faltantes críticos...\")\n",
    "    critical_columns = ['champion', 'win', 'kills', 'deaths', 'assists']\n",
    "    before_drop = len(df)\n",
    "    df_clean = df.dropna(subset=critical_columns)\n",
    "    after_drop = len(df_clean)\n",
    "    print(f\"   Filas eliminadas: {before_drop - after_drop}\")\n",
    "    \n",
    "    # 2. Limpiar espacios en blanco en columnas de texto\n",
    "    print(\"\\n2. Limpiando espacios en blanco...\")\n",
    "    text_columns = df_clean.select_dtypes(include=['object']).columns\n",
    "    for col in text_columns:\n",
    "        df_clean[col] = df_clean[col].astype(str).str.strip()\n",
    "    \n",
    "    # 3. Convertir tipos de datos\n",
    "    print(\"\\n3. Convirtiendo tipos de datos...\")\n",
    "    numeric_columns = ['win', 'kills', 'deaths', 'assists', 'gold', 'damage', 'damagetaken']\n",
    "    for col in numeric_columns:\n",
    "        if col in df_clean.columns:\n",
    "            df_clean[col] = pd.to_numeric(df_clean[col], errors='coerce')\n",
    "    \n",
    "    # 4. Manejar valores faltantes en columnas numéricas\n",
    "    print(\"\\n4. Manejando valores faltantes en columnas numéricas...\")\n",
    "    for col in numeric_columns:\n",
    "        if col in df_clean.columns:\n",
    "            missing_count = df_clean[col].isnull().sum()\n",
    "            if missing_count > 0:\n",
    "                df_clean[col] = df_clean[col].fillna(0)\n",
    "                print(f\"   {col}: {missing_count} valores faltantes rellenados con 0\")\n",
    "    \n",
    "    # 5. Filtrar datos inconsistentes\n",
    "    print(\"\\n5. Filtrando datos inconsistentes...\")\n",
    "    # Eliminar filas donde kills, deaths, assists son negativos\n",
    "    invalid_stats = (df_clean['kills'] < 0) | (df_clean['deaths'] < 0) | (df_clean['assists'] < 0)\n",
    "    invalid_count = invalid_stats.sum()\n",
    "    df_clean = df_clean[~invalid_stats]\n",
    "    print(f\"   Filas con estadísticas negativas eliminadas: {invalid_count}\")\n",
    "    \n",
    "    # 6. Validar rangos de datos\n",
    "    print(\"\\n6. Validando rangos de datos...\")\n",
    "    if 'win' in df_clean.columns:\n",
    "        invalid_wins = ~df_clean['win'].isin([0, 1])\n",
    "        invalid_win_count = invalid_wins.sum()\n",
    "        if invalid_win_count > 0:\n",
    "            df_clean = df_clean[~invalid_wins]\n",
    "            print(f\"   Filas con valores de win inválidos eliminadas: {invalid_win_count}\")\n",
    "    \n",
    "    final_shape = df_clean.shape\n",
    "    print(f\"\\n=== RESUMEN DE LIMPIEZA ===\")\n",
    "    print(f\"Forma original: {original_shape}\")\n",
    "    print(f\"Forma final: {final_shape}\")\n",
    "    print(f\"Filas eliminadas: {original_shape[0] - final_shape[0]}\")\n",
    "    print(f\"Porcentaje de datos conservados: {(final_shape[0]/original_shape[0])*100:.1f}%\")\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "# Aplicar limpieza a campeones\n",
    "champions_clean = clean_champions_data_detailed(champions_raw.copy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Limpieza de Datos de Partidos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_matches_data_detailed(df):\n",
    "    \"\"\"Limpia datos de partidos con explicaciones detalladas\"\"\"\n",
    "    print(\"=== LIMPIEZA DE DATOS DE PARTIDOS ===\")\n",
    "    original_shape = df.shape\n",
    "    \n",
    "    # 1. Limpiar columnas de texto\n",
    "    print(\"\\n1. Limpiando columnas de texto...\")\n",
    "    text_columns = df.select_dtypes(include=['object']).columns\n",
    "    for col in text_columns:\n",
    "        df[col] = df[col].astype(str).str.strip()\n",
    "    \n",
    "    # 2. Convertir fechas usando pandas\n",
    "    print(\"\\n2. Convirtiendo fechas...\")\n",
    "    if 'date' in df.columns:\n",
    "        df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "        invalid_dates = df['date'].isnull().sum()\n",
    "        if invalid_dates > 0:\n",
    "            print(f\"   Fechas inválidas encontradas: {invalid_dates}\")\n",
    "            df = df.dropna(subset=['date'])\n",
    "    \n",
    "    # 3. Convertir columnas numéricas usando pandas\n",
    "    print(\"\\n3. Convirtiendo columnas numéricas...\")\n",
    "    numeric_columns = ['duration', 'team1_kills', 'team2_kills', 'team1_gold', 'team2_gold']\n",
    "    for col in numeric_columns:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    \n",
    "    # 4. Manejar valores faltantes\n",
    "    print(\"\\n4. Manejando valores faltantes...\")\n",
    "    for col in numeric_columns:\n",
    "        if col in df.columns:\n",
    "            missing_count = df[col].isnull().sum()\n",
    "            if missing_count > 0:\n",
    "                df[col] = df[col].fillna(0)\n",
    "                print(f\"   {col}: {missing_count} valores faltantes rellenados con 0\")\n",
    "    \n",
    "    # 5. Validar consistencia de datos\n",
    "    print(\"\\n5. Validando consistencia de datos...\")\n",
    "    # Duración debe ser positiva\n",
    "    invalid_duration = df['duration'] <= 0\n",
    "    invalid_duration_count = invalid_duration.sum()\n",
    "    if invalid_duration_count > 0:\n",
    "        df = df[~invalid_duration]\n",
    "        print(f\"   Partidos con duración inválida eliminados: {invalid_duration_count}\")\n",
    "    \n",
    "    # Kills no pueden ser negativos\n",
    "    invalid_kills = (df['team1_kills'] < 0) | (df['team2_kills'] < 0)\n",
    "    invalid_kills_count = invalid_kills.sum()\n",
    "    if invalid_kills_count > 0:\n",
    "        df = df[~invalid_kills]\n",
    "        print(f\"   Partidos con kills negativos eliminados: {invalid_kills_count}\")\n",
    "    \n",
    "    final_shape = df.shape\n",
    "    print(f\"\\n=== RESUMEN DE LIMPIEZA ===\")\n",
    "    print(f\"Forma original: {original_shape}\")\n",
    "    print(f\"Forma final: {final_shape}\")\n",
    "    print(f\"Filas eliminadas: {original_shape[0] - final_shape[0]}\")\n",
    "    print(f\"Porcentaje de datos conservados: {(final_shape[0]/original_shape[0])*100:.1f}%\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Aplicar limpieza a partidos\n",
    "matches_clean = clean_matches_data_detailed(matches_raw.copy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Limpieza de Datos de Jugadores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_players_data_detailed(df):\n",
    "    \"\"\"Limpia datos de jugadores con explicaciones detalladas\"\"\"\n",
    "    print(\"=== LIMPIEZA DE DATOS DE JUGADORES ===\")\n",
    "    original_shape = df.shape\n",
    "    \n",
    "    # 1. Eliminar filas con valores faltantes críticos\n",
    "    print(\"\\n1. Eliminando filas con valores faltantes críticos...\")\n",
    "    critical_columns = ['player', 'team', 'champion', 'win']\n",
    "    before_drop = len(df)\n",
    "    df_clean = df.dropna(subset=critical_columns)\n",
    "    after_drop = len(df_clean)\n",
    "    print(f\"   Filas eliminadas: {before_drop - after_drop}\")\n",
    "    \n",
    "    # 2. Limpiar columnas de texto\n",
    "    print(\"\\n2. Limpiando columnas de texto...\")\n",
    "    text_columns = df_clean.select_dtypes(include=['object']).columns\n",
    "    for col in text_columns:\n",
    "        df_clean[col] = df_clean[col].astype(str).str.strip()\n",
    "    \n",
    "    # 3. Convertir columnas numéricas usando pandas\n",
    "    print(\"\\n3. Convirtiendo columnas numéricas...\")\n",
    "    numeric_columns = ['win', 'kills', 'deaths', 'assists', 'gold', 'damage', 'damagetaken']\n",
    "    for col in numeric_columns:\n",
    "        if col in df_clean.columns:\n",
    "            df_clean[col] = pd.to_numeric(df_clean[col], errors='coerce')\n",
    "    \n",
    "    # 4. Manejar valores faltantes\n",
    "    print(\"\\n4. Manejando valores faltantes...\")\n",
    "    for col in numeric_columns:\n",
    "        if col in df_clean.columns:\n",
    "            missing_count = df_clean[col].isnull().sum()\n",
    "            if missing_count > 0:\n",
    "                df_clean[col] = df_clean[col].fillna(0)\n",
    "                print(f\"   {col}: {missing_count} valores faltantes rellenados con 0\")\n",
    "    \n",
    "    # 5. Filtrar datos inconsistentes usando numpy\n",
    "    print(\"\\n5. Filtrando datos inconsistentes...\")\n",
    "    # Eliminar filas con estadísticas negativas\n",
    "    invalid_stats = (df_clean['kills'] < 0) | (df_clean['deaths'] < 0) | (df_clean['assists'] < 0)\n",
    "    invalid_count = invalid_stats.sum()\n",
    "    df_clean = df_clean[~invalid_stats]\n",
    "    print(f\"   Filas con estadísticas negativas eliminadas: {invalid_count}\")\n",
    "    \n",
    "    # Validar valores de win usando numpy\n",
    "    invalid_wins = ~df_clean['win'].isin([0, 1])\n",
    "    invalid_win_count = invalid_wins.sum()\n",
    "    if invalid_win_count > 0:\n",
    "        df_clean = df_clean[~invalid_wins]\n",
    "        print(f\"   Filas con valores de win inválidos eliminadas: {invalid_win_count}\")\n",
    "    \n",
    "    # 6. Eliminar jugadores con nombres vacíos o muy cortos\n",
    "    print(\"\\n6. Filtrando nombres de jugadores...\")\n",
    "    short_names = df_clean['player'].str.len() < 2\n",
    "    short_names_count = short_names.sum()\n",
    "    df_clean = df_clean[~short_names]\n",
    "    print(f\"   Filas con nombres muy cortos eliminadas: {short_names_count}\")\n",
    "    \n",
    "    final_shape = df_clean.shape\n",
    "    print(f\"\\n=== RESUMEN DE LIMPIEZA ===\")\n",
    "    print(f\"Forma original: {original_shape}\")\n",
    "    print(f\"Forma final: {final_shape}\")\n",
    "    print(f\"Filas eliminadas: {original_shape[0] - final_shape[0]}\")\n",
    "    print(f\"Porcentaje de datos conservados: {(final_shape[0]/original_shape[0])*100:.1f}%\")\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "# Aplicar limpieza a jugadores\n",
    "players_clean = clean_players_data_detailed(players_raw.copy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Análisis de Impacto de la Limpieza con Visualizaciones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear visualización del impacto de la limpieza usando numpy y pandas\n",
    "datasets = ['Champions', 'Matches', 'Players']\n",
    "original_sizes = np.array([champions_raw.shape[0], matches_raw.shape[0], players_raw.shape[0]])\n",
    "clean_sizes = np.array([champions_clean.shape[0], matches_clean.shape[0], players_clean.shape[0]])\n",
    "\n",
    "# Crear DataFrame para análisis usando pandas\n",
    "impact_df = pd.DataFrame({\n",
    "    'Dataset': datasets,\n",
    "    'Original': original_sizes,\n",
    "    'Limpio': clean_sizes,\n",
    "    'Eliminados': original_sizes - clean_sizes,\n",
    "    'Porcentaje_Conservado': (clean_sizes / original_sizes) * 100\n",
    "})\n",
    "\n",
    "print(\"=== ANÁLISIS DE IMPACTO DE LA LIMPIEZA ===\")\n",
    "print(impact_df)\n",
    "\n",
    "# Crear visualizaciones\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Gráfico de barras comparativo usando numpy para posicionamiento\n",
    "x = np.arange(len(datasets))\n",
    "width = 0.35\n",
    "\n",
    "ax1.bar(x - width/2, original_sizes, width, label='Original', alpha=0.8, color='red')\n",
    "ax1.bar(x + width/2, clean_sizes, width, label='Limpio', alpha=0.8, color='green')\n",
    "\n",
    "ax1.set_xlabel('Dataset')\n",
    "ax1.set_ylabel('Número de Filas')\n",
    "ax1.set_title('Impacto de la Limpieza de Datos')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(datasets)\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Gráfico de porcentaje de datos conservados\n",
    "conservation_pct = impact_df['Porcentaje_Conservado'].values\n",
    "bars = ax2.bar(datasets, conservation_pct, alpha=0.8, color='blue')\n",
    "ax2.set_ylabel('Porcentaje de Datos Conservados (%)')\n",
    "ax2.set_title('Porcentaje de Datos Conservados Después de la Limpieza')\n",
    "ax2.set_ylim(0, 100)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Añadir valores en las barras usando numpy\n",
    "for bar, pct in zip(bars, conservation_pct):\n",
    "    height = bar.get_height()\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "             f'{pct:.1f}%', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Mostrar resumen numérico usando pandas\n",
    "print(\"\\n=== RESUMEN DEL IMPACTO DE LA LIMPIEZA ===\")\n",
    "for _, row in impact_df.iterrows():\n",
    "    print(f\"{row['Dataset']}:\")\n",
    "    print(f\"  Original: {row['Original']:,} filas\")\n",
    "    print(f\"  Limpio: {row['Limpio']:,} filas\")\n",
    "    print(f\"  Eliminadas: {row['Eliminados']:,} filas ({100-row['Porcentaje_Conservado']:.1f}%)\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Análisis Estadístico de los Datos Limpios\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis estadístico usando pandas y numpy\n",
    "def analyze_clean_data_stats(df, dataset_name):\n",
    "    \"\"\"Realiza análisis estadístico de los datos limpios\"\"\"\n",
    "    print(f\"\\n=== ANÁLISIS ESTADÍSTICO: {dataset_name.upper()} ===\")\n",
    "    \n",
    "    # Estadísticas descriptivas básicas usando pandas\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    if len(numeric_cols) > 0:\n",
    "        print(f\"\\nEstadísticas descriptivas de columnas numéricas:\")\n",
    "        stats_df = df[numeric_cols].describe()\n",
    "        print(stats_df)\n",
    "        \n",
    "        # Análisis de correlaciones usando pandas\n",
    "        if len(numeric_cols) > 1:\n",
    "            print(f\"\\nMatriz de correlaciones:\")\n",
    "            corr_matrix = df[numeric_cols].corr()\n",
    "            print(corr_matrix.round(3))\n",
    "    \n",
    "    # Análisis de valores únicos usando pandas\n",
    "    text_cols = df.select_dtypes(include=['object']).columns\n",
    "    if len(text_cols) > 0:\n",
    "        print(f\"\\nAnálisis de columnas categóricas:\")\n",
    "        for col in text_cols[:5]:  # Solo las primeras 5 columnas\n",
    "            unique_count = df[col].nunique()\n",
    "            most_common = df[col].mode().iloc[0] if not df[col].mode().empty else \"N/A\"\n",
    "            print(f\"  {col}: {unique_count} valores únicos, más común: '{most_common}'\")\n",
    "    \n",
    "    # Análisis de distribución usando numpy\n",
    "    if 'win' in df.columns:\n",
    "        win_distribution = df['win'].value_counts()\n",
    "        win_rate = (win_distribution.get(1, 0) / len(df)) * 100\n",
    "        print(f\"\\nDistribución de victorias:\")\n",
    "        print(f\"  Victoria: {win_distribution.get(1, 0)} ({win_rate:.1f}%)\")\n",
    "        print(f\"  Derrota: {win_distribution.get(0, 0)} ({100-win_rate:.1f}%)\")\n",
    "    \n",
    "    return stats_df if len(numeric_cols) > 0 else None\n",
    "\n",
    "# Realizar análisis estadístico\n",
    "champions_stats = analyze_clean_data_stats(champions_clean, \"Champions\")\n",
    "matches_stats = analyze_clean_data_stats(matches_clean, \"Matches\")\n",
    "players_stats = analyze_clean_data_stats(players_clean, \"Players\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Guardar Datos Limpios y Conclusiones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar datos limpios usando pandas\n",
    "champions_clean.to_csv('../league-of-legends-worlds/data/02_intermediate/champions_clean.csv', index=False, encoding='latin-1')\n",
    "matches_clean.to_csv('../league-of-legends-worlds/data/02_intermediate/matches_clean.csv', index=False, encoding='latin-1')\n",
    "players_clean.to_csv('../league-of-legends-worlds/data/02_intermediate/players_clean.csv', index=False, encoding='latin-1')\n",
    "\n",
    "print(\"✅ Datos limpios guardados exitosamente usando pandas\")\n",
    "print(\"\\nArchivos guardados:\")\n",
    "print(\"- ../league-of-legends-worlds/data/02_intermediate/champions_clean.csv\")\n",
    "print(\"- ../league-of-legends-worlds/data/02_intermediate/matches_clean.csv\")\n",
    "print(\"- ../league-of-legends-worlds/data/02_intermediate/players_clean.csv\")\n",
    "\n",
    "# Crear resumen final usando pandas y numpy\n",
    "summary_data = {\n",
    "    'Dataset': ['Champions', 'Matches', 'Players'],\n",
    "    'Filas_Originales': [champions_raw.shape[0], matches_raw.shape[0], players_raw.shape[0]],\n",
    "    'Filas_Limpias': [champions_clean.shape[0], matches_clean.shape[0], players_clean.shape[0]],\n",
    "    'Columnas_Originales': [champions_raw.shape[1], matches_raw.shape[1], players_raw.shape[1]],\n",
    "    'Columnas_Limpias': [champions_clean.shape[1], matches_clean.shape[1], players_clean.shape[1]]\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "summary_df['Filas_Eliminadas'] = summary_df['Filas_Originales'] - summary_df['Filas_Limpias']\n",
    "summary_df['Porcentaje_Conservado'] = (summary_df['Filas_Limpias'] / summary_df['Filas_Originales']) * 100\n",
    "\n",
    "print(\"\\n=== RESUMEN FINAL DE LA LIMPIEZA ===\")\n",
    "print(summary_df.to_string(index=False))\n",
    "\n",
    "# Calcular estadísticas generales usando numpy\n",
    "total_original = np.sum(summary_df['Filas_Originales'])\n",
    "total_clean = np.sum(summary_df['Filas_Limpias'])\n",
    "total_removed = total_original - total_clean\n",
    "overall_conservation = (total_clean / total_original) * 100\n",
    "\n",
    "print(f\"\\n=== ESTADÍSTICAS GENERALES ===\")\n",
    "print(f\"Total de filas originales: {total_original:,}\")\n",
    "print(f\"Total de filas después de limpieza: {total_clean:,}\")\n",
    "print(f\"Total de filas eliminadas: {total_removed:,}\")\n",
    "print(f\"Porcentaje general de conservación: {overall_conservation:.1f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Conclusiones de la Limpieza de Datos\n",
    "\n",
    "### Resumen de Acciones Realizadas:\n",
    "\n",
    "1. **Eliminación de valores faltantes críticos**: Se eliminaron filas con información esencial faltante\n",
    "2. **Limpieza de texto**: Se eliminaron espacios en blanco y se estandarizaron formatos usando pandas\n",
    "3. **Conversión de tipos**: Se convirtieron columnas a los tipos de datos apropiados usando pandas\n",
    "4. **Manejo de valores faltantes**: Se rellenaron valores faltantes con valores apropiados (0 para estadísticas)\n",
    "5. **Filtrado de inconsistencias**: Se eliminaron filas con datos lógicamente incorrectos usando numpy\n",
    "6. **Validación de rangos**: Se verificaron rangos de valores para asegurar consistencia\n",
    "\n",
    "### Uso de Librerías:\n",
    "\n",
    "- **Pandas**: Para manipulación de DataFrames, conversión de tipos, manejo de valores faltantes, y análisis estadístico\n",
    "- **NumPy**: Para operaciones matemáticas, arrays, y validaciones lógicas\n",
    "- **Matplotlib/Seaborn**: Para visualizaciones del impacto de la limpieza\n",
    "\n",
    "### Impacto en la Calidad de Datos:\n",
    "\n",
    "- **Datos más consistentes**: Eliminación de valores anómalos y inconsistentes\n",
    "- **Tipos de datos correctos**: Conversión apropiada para análisis posterior\n",
    "- **Menos valores faltantes**: Manejo sistemático de datos faltantes\n",
    "- **Mayor confiabilidad**: Validación de rangos y consistencia lógica\n",
    "\n",
    "### Próximos Pasos:\n",
    "\n",
    "Los datos limpios están listos para:\n",
    "1. **Ingeniería de características**: Creación de variables derivadas\n",
    "2. **Análisis exploratorio**: Identificación de patrones y tendencias\n",
    "3. **Modelado**: Desarrollo de modelos de machine learning\n",
    "4. **Validación**: Verificación de la calidad de los modelos\n",
    "\n",
    "### Ventajas del Enfoque en Notebooks:\n",
    "\n",
    "- **Transparencia**: Cada paso de limpieza está documentado y explicado\n",
    "- **Reproducibilidad**: El proceso puede ser ejecutado múltiples veces\n",
    "- **Interactividad**: Permite explorar los datos y ajustar el proceso\n",
    "- **Visualización**: Gráficos que muestran el impacto de cada acción\n",
    "- **Educativo**: Facilita el entendimiento del proceso de limpieza\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kedro (league_of_legends_worlds)",
   "language": "python",
   "name": "kedro_league_of_legends_worlds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
